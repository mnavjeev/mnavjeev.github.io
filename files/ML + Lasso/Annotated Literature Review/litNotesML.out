\BOOKMARK [1][-]{section.1}{Generalized Random Forests; Susan Athey, Julie Tibshirani, Setfan Wager \(AOS, 2018\)}{}% 1
\BOOKMARK [2][-]{subsection.1.1}{Introduction}{section.1}% 2
\BOOKMARK [3][-]{subsubsection.1.1.1}{Related Work}{subsection.1.1}% 3
\BOOKMARK [2][-]{subsection.1.2}{Generalized Random Forests}{section.1}% 4
\BOOKMARK [3][-]{subsubsection.1.2.1}{Splitting to Maximize Heterogeneity}{subsection.1.2}% 5
\BOOKMARK [3][-]{subsubsection.1.2.2}{The Gradient Tree Algorithm}{subsection.1.2}% 6
\BOOKMARK [2][-]{subsection.1.3}{Asymptotic Analysis}{section.1}% 7
\BOOKMARK [3][-]{subsubsection.1.3.1}{A Central Limit Theorem for Generalized Random Forests}{subsection.1.3}% 8
\BOOKMARK [2][-]{subsection.1.4}{Confidence Intervals via the Delta Method}{section.1}% 9
\BOOKMARK [3][-]{subsubsection.1.4.1}{Consistency of the Bootstrap of Little Bags}{subsection.1.4}% 10
\BOOKMARK [1][-]{section.2}{Deep Learning in NPR Benedikt Bauer and Michael Kohler \(AOS, 2019\)}{}% 11
\BOOKMARK [2][-]{subsection.2.1}{Introduction}{section.2}% 12
\BOOKMARK [3][-]{subsubsection.2.1.1}{Rate of Convergence}{subsection.2.1}% 13
\BOOKMARK [3][-]{subsubsection.2.1.2}{Curse of dimensionality}{subsection.2.1}% 14
\BOOKMARK [3][-]{subsubsection.2.1.3}{Neural Networks}{subsection.2.1}% 15
\BOOKMARK [3][-]{subsubsection.2.1.4}{Main Results}{subsection.2.1}% 16
\BOOKMARK [3][-]{subsubsection.2.1.5}{Notation}{subsection.2.1}% 17
\BOOKMARK [2][-]{subsection.2.2}{Nonparametric Regression Estimation by Multilayer Feedforward Neural Networks}{section.2}% 18
\BOOKMARK [2][-]{subsection.2.3}{Application to Simulated Data}{section.2}% 19
\BOOKMARK [2][-]{subsection.2.4}{Proofs}{section.2}% 20
\BOOKMARK [1][-]{section.3}{NPR Using Deep Neural Networks Johannes Schmidt-Hieber \(ArXiv, 2017\)}{}% 21
\BOOKMARK [2][-]{subsection.3.1}{Introduction}{section.3}% 22
\BOOKMARK [2][-]{subsection.3.2}{Mathematical Definition of Multilayer Neural Networks}{section.3}% 23
\BOOKMARK [2][-]{subsection.3.3}{Main Results}{section.3}% 24
\BOOKMARK [1][-]{section.4}{Central Limit Theorems and Bootstrap in High Dimensions Victor Chernozhukov, Denis Chetverikov, Kengo Kato \(AoP 2017\)}{}% 25
\BOOKMARK [2][-]{subsection.4.1}{Introduction}{section.4}% 26
\BOOKMARK [2][-]{subsection.4.2}{High-dimensional CLT for hyperrectangles}{section.4}% 27
\BOOKMARK [2][-]{subsection.4.3}{High-dimensional CLT for simple and sparsely convex sets}{section.4}% 28
\BOOKMARK [3][-]{subsubsection.4.3.1}{Simple Convex Sets}{subsection.4.3}% 29
\BOOKMARK [3][-]{subsubsection.4.3.2}{Sparsely Convex Sets}{subsection.4.3}% 30
\BOOKMARK [1][-]{section.5}{Sparse Principal Component Analysis Hui Zou, Trevor Hastie, Robert Tisbirani \(JCGS, 2006\)}{}% 31
\BOOKMARK [2][-]{subsection.5.1}{Introduction}{section.5}% 32
\BOOKMARK [2][-]{subsection.5.2}{Motivation and Details of SPCA}{section.5}% 33
\BOOKMARK [3][-]{subsubsection.5.2.1}{Direct Sparse Approximation}{subsection.5.2}% 34
\BOOKMARK [3][-]{subsubsection.5.2.2}{Sparse Principal Components Based on the SPCA Criterion}{subsection.5.2}% 35
\BOOKMARK [1][-]{section.6}{Deep IVJason Hartford, Greg Lewis, Kevin Leyton Brown , Matt Taddy}{}% 36
\BOOKMARK [2][-]{subsection.6.1}{Introduction}{section.6}% 37
\BOOKMARK [2][-]{subsection.6.2}{Counterfactual Prediction}{section.6}% 38
\BOOKMARK [2][-]{subsection.6.3}{Estimating and Validating DeepIV}{section.6}% 39
\BOOKMARK [3][-]{subsubsection.6.3.1}{Optimization for DeepIV Networks}{subsection.6.3}% 40
