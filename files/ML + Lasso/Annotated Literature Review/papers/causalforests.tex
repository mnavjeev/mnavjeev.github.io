%!TEX root = /Users/manunavjeevan/Documents/GitHub//mnavjeev.github.io/files/ML + Lasso/Annotated Literature Review/litNotesML.tex

\section{Causal Forests \text{\small Stegan Wager and Susan Athey (JASA, 2018)}}

Full paper title is ``Estimation and Inference of Heterogeneous Treatment Effects using Random Forests.'' The article appeared in the Journal of the American Statistical Association in June 2018. It can be found on the JASA website \href{https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1319839}{here}. 

\subsection{Introduction}

In many applications, want to use data to draw inferences about the causal effect of a treatment. Examples include medical studies about the effect of a druf on health outcomes, studies of the impact of advertising or marketing offers on consumer purchases, evaluations of the effectiveness of government programs or public policies. Historically, most datasets have been too small to meaningfully explore heterogeneity of treatment effects beyond dividing the sample into a few subgroups. Recently, however, there has been an explosion of empirical setting where it is potentially feasible to cutomize estimates for individuals.

An impediment to exploring heterogeneous treatment effects is the fear that researchers will iteratively search for subgroups with treatment effects. Paper develops a nonparametrics approach to do this. 

\subsection{Causal Forests}

\subsubsection{Treatment Estimation with Unconfoundedness}

Suppose we have access to $n$ i.i.d training examples labeled $i = 1,\dots,n$, each of which consists of a feature vector $X_i \in [0,1]^d$, a response $Y_i \in \SR$, and a treatment indicator $W_i \in \{0,1\}.$ Following the potential outcomes framework of Neyman (1923) and Rubin (1974), then posit the existence of potential outcomes $Y_i^{(1)}$ and $Y_i^{(0)}$. Define the treatment effect at $x$ as 
\begin{equation}
	\label{eq:cf-1}
	\tau(x) = \E[Y_i^\Pone - Y_i^\Pzero | X_i = x]
\end{equation}
Goal is to estimate the function $\tau(x)$. The main difficulty is that we can only ever observe one of the two potential outcomes $Y_i^\Pzero$ and $Y_i^\Pone$ for any individual and so cannot directly train ML model on the difference. 

In general, cannot estimate $\tau(x)$ directly from the observed data $(X_i, Y_i, W_i)$ without further restrictions on the Data Generating Process. A standard way to make progress is to make an unconfoundedness assumption. This is stated formally 
\begin{equation}
	\label{eq:cf-2}
	\left\{Y_i^\Pzero, Y_i^\Pone \right\} \perp W_i \mid X_i;\footnote{Some helpful definitions are provided here\begin{definition*}[Independence]
	Let $(\Omega, \calF, \P)$ be a probability space. Then, sub-$\sigma$-fields $\calG_1, \dots, \calG_n\subset \calF$ are said to be independent if 
	\[\P(G_1\cdots\dots\cdot G_n) = \P(G_1)\cdot\dots\P(G_n), \forall G_i \in \calG_i, i = 1, \dots, n\]
	An infinite collection of sub sigma fields is said to be independent if each finite collection is independent.
		\end{definition*}
		\begin{definition*}[Conditional Probability Distribution]
			Let $T$ be an $\calF\setminus\calB$ measurable map from a probability space $(\Omega, \calF, \P)$ into a measurable space $(\calT, \calB)$. Let $\mathbb{Q}$ equal $T\P$, the distribution of $T$ under $\P$. Call a family $\calP = \{\P_t: t\in \calT\}$ of probability measures on $\calF$ the \emph{conditional probability distribution} of $\P$ given $T$ if 
			\begin{enumerate}
				\item $\P_t\{T \neq t\} = 0$ for $\mathbb{Q}$-almost all $t \in \calT$.
				\item The map $t\mapsto \P_t^\omega f(\omega)$ is $\calB$-measurable and $\P^\omega f(\omega) = \mathbb{Q}^t\P_t^\omega f(\omega)$, for each $f \in \calM^+(\Omega, \calF)$, the set of all positive measurable functions.
			\end{enumerate}
		\end{definition*}}
\end{equation}
Motivation behind unconfoundedness is that, given continuity assumptions, it effectively implies that one can treat nearby observations in $x$-space as having come from a randomized experiment. Thus, nearest-neighbor matching and other local methods will, in general, be consistent for $\tau(x)$.

An immediate consequence of unconfoundedness is that 
\begin{equation}
	\label{eq:cf-3}
	\E\left[Y_i\left(\frac{W_i}{e(x)}- \frac{1 - W_i}{1-e(x)}\right)\mid X_i = x \right] = \tau(x),\hbox{ }\text{ where }e(x) = \E[W_i | X_i = x]\hbox{ }\footnote{This is the propensity score design}
\end{equation}
Many early applications of ML to causal inference effectively reduced to estimating $e(x)$ and plugging into \eqref{eq:cf-3} above. This paper takes a more indirect approach: show that, under regularity assumptions, causal forests can use \eqref{eq:cf-2} to achieve consistency without needing to explicitly estimate the propensity $e(x)$.

\subsubsection{From Regression Trees to Causal Forests}

At a high level, trees and forests can be thought of as nearest neighbor methods with an adaptive neighborhood metric. Advantage of trees is that leaves can be narrower along the directions in which the signal is changing fast and wider along the other directions. 

This section seeks to build causal trees that resemble their regression analogues as closely as possilbe. Suppose first that we only observe independent samples $(X_i, Y_i)$ and want to build a CART regression tree. Start by recursively splitting the feature space until have partitioned it into a set of leaves $L$, each of which only contains a few training samples. Then, given a test point $x$, evaluate the prediction $\hat{\mu}(x)$ by identifying the leaf $L(x)$ containing $x$ and setting 
\begin{equation}
	\label{eq:cf-4}
	\hat{\mu}(x) = \frac{1}{|\{i: X_i \in L(x)\}|} \sum_{\{i:X_i \in L(x)\}} Y_i 
\end{equation}
That is, just setting $\hat{\mu}(x)$ to be the average inside the leaf containing $x$. Heuristically, this strategy is well motivated if the leaf $L(x)$ is small enough if the responses inside the leaf are roughly identically distributed. In the context of causal trees, analagously want to thing of the leaves as small enough that the $(Y_i, W_i)$ pairs corresponding to the indices $i$ for which $i \in L(x)$ act as though they had come from a randomized experiment. 

In the context of causal trees, analogously want to think of the leaves as small enough that the $(Y_i, W_i)$ pairs corresponding to the indices $i$ for which $i \in L(x)$ act as though they had come from a randomized experiment. Then it is natural to estimate the treatment effect for any $x\in L$ as 
\begin{equation}
	\label{eq:cf-5}
	\hat{\tau}(x) = \frac{1}{|\{i: W_i = 1, X_i \in L\}|}\sum_{i: W_i = 1, X_i \in L}Y_i - \frac{1}{|\{i: W_i = 0, X_i \in L\}|} \sum_{i:W_i = 0, X_i \in L} Y_i\hbox{ }\footnote{ Question: Why bother having one regression tree for both $Y(1)$ and $Y(0)$? This assumes that the heterogeneity is the same. It seems like we'd get better predictive results just doing two seperate regression trees.}
\end{equation} 
Maybe the advantage is consolidating for inference?

\subsubsection{Asymptotic Inference with Causal Forests}

Results require some conditions on the forest-growing scheme. The trees used to build the forest must be grown on subsamples of the training data, and the splitting rule must not ``inappropriately'' incorporate information about the outcomes $Y_i$ as discussed formally below. However, given these high level conditions, obtain a widely applicable consistency result.

First result is that the causal forests are consistent for the true treatment effect $\tau(x)$. To achieve pointwise consistency, need to assume that the conditional mean functions $\E[Y^\Pzero| X = x]$ and $\E[Y^\Pone | X = x]$ are both Lipschitz continuous. This assumption is fairly standard in the literature. Also impose common support, $\exists \eps > 0:$
\begin{equation}
	\label{eq:cf-6}
	\eps < \P[W = 1| X = x] < 1-\eps
\end{equation}
Beyond consistency, in order to do statistical inference on the basis of the estimated treatment effects $\tau(x)$, need to do inference. Paper shows that, 
\begin{equation}
	\label{eq:cf-7}
	\left(\hat{\tau}(x) - \tau(x)\right) / \sqrt{\Var[\hat{\tau}(x)]} \wcov N(0,1)
\end{equation}
Under the conditions required for consistency, provided the subsample size s scales with $n^\beta$ for some $\beta_{min} < \beta < 1$.

Moreover, show that the asymptotic variance of causal forests can be accurately estimated. To do so, use the infinitesimal jackknife for random forests by Efron (2014) and Wager et al. (2014). Method assumes that we have taken the number of trees $B$ to be large enough that the Monte Carlo variability of the forest does not matter, and only measures the randomness in $\hat{\tau}(x)$ due to the training sample. 

\subsubsection{Honest Trees and Forests}

In our discussion so far, have emphasized the flexible nature of results. For a wide variety of causal forests that can be tailored to the application area, achieve both consistency and centered asymptotic normality, provided the sub-sample size $s$ scales at an appropriate rate. Results require that individual trees satisfy a fairly strong condition: honesty. A tree is honest if, for each training example $i$, it only uses the response $Y_i$ to estimate the within-leaf treatment effect $\tau$ using \eqref{eq:cf-5} or to decide where to place the splits, but not both. Paper discusses two causal forest algorithms that satisfy this condition.

First algorithm, called double-sample tree, achieves honesty by dividing its training subsample into two halves $\calI$ and $\calJ$. Then, uses the $\calJ$-sample to place the splits while holding out the $\calI$-sample to do within-leaf estimation. Re-randomize $\calI\setminus\calJ$ splits over each subsample so that, although no one data point can be used for split selection and leaf estimation in a single tree, each data point will participate in both $\calI$ and $\calJ$ sample of some trees. Initial objective was to reduce bias, but find that double-sample trees can improve MSE as well.

Another way to build honest trees is to ignore the outcome data $Y_i$ when placing splits and instead first train a classification tree for the treatment assignments $W_i$. Such propensity trees can be particularly useful in observational studies where want to minimize bias due to variation in $e(x)$.










